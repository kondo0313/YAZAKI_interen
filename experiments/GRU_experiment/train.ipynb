{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/home/code/mlflow')\n",
    "import models.Preprocessing as pre\n",
    "import models.utils as ut\n",
    "import models.GRU as gru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/home/code/data/processed/week_dataset.csv'\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前処理用のパラメータ設定\n",
    "week_1 = 7\n",
    "week_2 = 14\n",
    "week_3 = 21\n",
    "\n",
    "weekly_mean_columns = ['Week Shipment']\n",
    "weekly_total_columns = ['Status']\n",
    "shift_unchange_name_columns = ['Status', 'Week Status', 'Week Shipment Mean', 'Week Status2']\n",
    "shift_change_name_columns = ['Temp', 'Week Temp']\n",
    "# env_columns1 = ['Temp-'+str(week_1), 'Week Temp-'+str(week_1)]\n",
    "# env_columns2 = ['Temp-'+str(week_2), 'Week Temp-'+str(week_2)]\n",
    "# env_columns3 = ['Temp-'+str(week_3), 'Week Temp-'+str(week_3)]\n",
    "\n",
    "env_columns = ['Temp-'+str(13), 'Week Temp-'+str(13)]\n",
    "\n",
    "cat_columns = ['Week Number']\n",
    "drop_columns = ['Target', 'Week', 'Week Start', 'Week End', 'Week Status2', 'Status', 'Teisyoku', \n",
    "                'Week Teisyoku', 'Week WNDDIR','Week WNDSPD', 'Week RHUM', 'Week PRCRIN_30MIN', \n",
    "                'Week SNWFLL_30MIN', 'Week WX', 'Week Solar', 'Week Rain', 'Week Pred Temp',\n",
    "                'WNDDIR', 'WNDSPD', 'RHUM', 'PRCRIN_30MIN', 'SNWFLL_30MIN', 'WX', 'Solar', 'Rain',\n",
    "                'Pred Temp', 'GLBRAD', 'GLBRAD_30MIN', 'Week GLBRAD', 'Week GLBRAD_30MIN',\n",
    "                'AIRTMP', 'Week AIRTMP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_week1 = df.copy()\n",
    "df_week2 = df.copy()\n",
    "df_week3 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m df_week1 \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 2\u001b[0m         \u001b[43mdf_week1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchange_column_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_index_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_status\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_weekday\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_weekly_total\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweekly_total_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_weekly_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweekly_mean_columns\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_week_status2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshift_unchange_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshift_unchange_name_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift_days\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweek_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshift_change_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshift_change_name_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshift_days\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweek_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;241m.\u001b[39mpipe(pre\u001b[38;5;241m.\u001b[39mchange_env_data, env_columns\u001b[38;5;241m=\u001b[39menv_columns)\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;241m.\u001b[39mpipe(pre\u001b[38;5;241m.\u001b[39madd_target, target_days\u001b[38;5;241m=\u001b[39mweek_1) \u001b[38;5;66;03m# Week Shipmentをズラす前に作成することに注意\u001b[39;00m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;241m.\u001b[39mpipe(pre\u001b[38;5;241m.\u001b[39madd_target2, target_days\u001b[38;5;241m=\u001b[39mweek_1) \u001b[38;5;66;03m# Week Shipmentをズラす前に作成することに注意\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;241m.\u001b[39mpipe(pre\u001b[38;5;241m.\u001b[39mshift_unchange_name, shift_columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWeek Shipment\u001b[39m\u001b[38;5;124m'\u001b[39m], shift_days\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m7\u001b[39m) \u001b[38;5;66;03m# Week Shipmentは1週間前のデータを使用\u001b[39;00m\n\u001b[1;32m     15\u001b[0m         \u001b[38;5;241m.\u001b[39mpipe(pre\u001b[38;5;241m.\u001b[39mdrop_columns, drop_columns\u001b[38;5;241m=\u001b[39mdrop_columns)\n\u001b[1;32m     16\u001b[0m         \u001b[38;5;241m.\u001b[39mpipe(pre\u001b[38;5;241m.\u001b[39mcategorize_columns, cat_columns\u001b[38;5;241m=\u001b[39mcat_columns)\n\u001b[1;32m     17\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/generic.py:5926\u001b[0m, in \u001b[0;36mNDFrame.pipe\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   5924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m   5925\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m common\u001b[38;5;241m.\u001b[39mpipe(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m), func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5926\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcommon\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/common.py:518\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m(obj, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/code/mlflow/models/Preprocessing.py:123\u001b[0m, in \u001b[0;36mshift_change_name\u001b[0;34m(df, shift_columns, shift_days)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshift_change_name\u001b[39m(df, shift_columns, shift_days):\n\u001b[1;32m    122\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m shift_columns:\n\u001b[0;32m--> 123\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m shift_day \u001b[38;5;129;01min\u001b[39;00m shift_days:\n\u001b[1;32m    124\u001b[0m             df[col\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;241m-\u001b[39mshift_day)] \u001b[38;5;241m=\u001b[39m df[col]\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m-\u001b[39mshift_day)\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "df_week1 = (\n",
    "        df_week1.pipe(pre.change_column_name)\n",
    "        .pipe(pre.set_index_date)\n",
    "        .pipe(pre.add_status)\n",
    "        .pipe(pre.add_weekday)\n",
    "        .pipe(pre.add_weekly_total, columns=weekly_total_columns)\n",
    "        .pipe(pre.add_weekly_mean, columns=weekly_mean_columns) \n",
    "        .pipe(pre.add_week_status2)\n",
    "        .pipe(pre.shift_unchange_name, shift_columns=shift_unchange_name_columns, shift_days=week_1)\n",
    "        .pipe(pre.shift_change_name, shift_columns=shift_change_name_columns, shift_days=[we]ek_1)\n",
    "        .pipe(pre.change_env_data, env_columns=env_columns)\n",
    "        .pipe(pre.add_target, target_days=week_1) # Week Shipmentをズラす前に作成することに注意\n",
    "        .pipe(pre.add_target2, target_days=week_1) # Week Shipmentをズラす前に作成することに注意\n",
    "        .pipe(pre.shift_unchange_name, shift_columns=['Week Shipment'], shift_days=-7) # Week Shipmentは1週間前のデータを使用\n",
    "        .pipe(pre.drop_columns, drop_columns=drop_columns)\n",
    "        .pipe(pre.categorize_columns, cat_columns=cat_columns)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_week2 = (\n",
    "        df_week2.pipe(pre.change_column_name)\n",
    "        .pipe(pre.set_index_date)\n",
    "        .pipe(pre.add_status)\n",
    "        .pipe(pre.add_weekday)\n",
    "        .pipe(pre.add_weekly_total, columns=weekly_total_columns)\n",
    "        .pipe(pre.add_weekly_mean, columns=weekly_mean_columns) \n",
    "        .pipe(pre.add_week_status2)\n",
    "        .pipe(pre.shift_unchange_name, shift_columns=shift_unchange_name_columns, shift_days=week_2)\n",
    "        .pipe(pre.shift_change_name, shift_columns=shift_change_name_columns, shift_days=13)\n",
    "        .pipe(pre.change_env_data, env_columns=env_columns)\n",
    "        .pipe(pre.add_target, target_days=week_2) # Week Shipmentをズラす前に作成することに注意\n",
    "        .pipe(pre.add_target2, target_days=week_2) # Week Shipmentをズラす前に作成することに注意\n",
    "        .pipe(pre.shift_unchange_name, shift_columns=['Week Shipment'], shift_days=-7) # Week Shipmentは1週間前のデータを使用\n",
    "        .pipe(pre.drop_columns, drop_columns=drop_columns)\n",
    "        .pipe(pre.categorize_columns, cat_columns=cat_columns)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_week3 = (\n",
    "        df_week3.pipe(pre.change_column_name)\n",
    "        .pipe(pre.set_index_date)\n",
    "        .pipe(pre.add_status)\n",
    "        .pipe(pre.add_weekday)\n",
    "        .pipe(pre.add_weekly_total, columns=weekly_total_columns)\n",
    "        .pipe(pre.add_weekly_mean, columns=weekly_mean_columns) \n",
    "        .pipe(pre.add_week_status2)\n",
    "        .pipe(pre.shift_unchange_name, shift_columns=shift_unchange_name_columns, shift_days=week_3)\n",
    "        .pipe(pre.shift_change_name, shift_columns=shift_change_name_columns, shift_days=13)\n",
    "        .pipe(pre.change_env_data, env_columns=env_columns)\n",
    "        .pipe(pre.add_target, target_days=week_3) # Week Shipmentをズラす前に作成することに注意\n",
    "        .pipe(pre.add_target2, target_days=week_3) # Week Shipmentをズラす前に作成することに注意\n",
    "        .pipe(pre.shift_unchange_name, shift_columns=['Week Shipment'], shift_days=-7) # Week Shipmentは1週間前のデータを使用\n",
    "        .pipe(pre.drop_columns, drop_columns=drop_columns)\n",
    "        .pipe(pre.categorize_columns, cat_columns=cat_columns)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Week Temp', 'Week High Temp', 'Week Low Temp', 'Week Shipment',\n",
       "       'Shipment', 'Temp', 'High Temp', 'Low Temp', 'Week Status',\n",
       "       'Week Shipment Mean', 'Temp-13', 'Week Temp-13', 'Target2',\n",
       "       'Week Number_1', 'Week Number_2', 'Week Number_3', 'Week Number_4',\n",
       "       'Week Number_5', 'Week Number_6', 'Week Number_7', 'Week Number_8',\n",
       "       'Week Number_9', 'Week Number_10', 'Week Number_11', 'Week Number_12',\n",
       "       'Week Number_13', 'Week Number_14', 'Week Number_15', 'Week Number_16',\n",
       "       'Week Number_17', 'Week Number_18', 'Week Number_19', 'Week Number_20',\n",
       "       'Week Number_21', 'Week Number_22', 'Week Number_23', 'Week Number_24',\n",
       "       'Week Number_25', 'Week Number_26', 'Week Number_27', 'Week Number_28',\n",
       "       'Week Number_29', 'Week Number_30', 'Week Number_31', 'Week Number_32',\n",
       "       'Week Number_33', 'Week Number_34', 'Week Number_35', 'Week Number_36',\n",
       "       'Week Number_37', 'Week Number_38', 'Week Number_39', 'Week Number_40',\n",
       "       'Week Number_41', 'Week Number_42', 'Week Number_43', 'Week Number_44',\n",
       "       'Week Number_45', 'Week Number_46', 'Week Number_47', 'Week Number_48',\n",
       "       'Week Number_49', 'Week Number_50', 'Week Number_51', 'Week Number_52',\n",
       "       'Week Number_53'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 学習に使用される特徴量の確認\n",
    "df_week2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ範囲を指定\n",
    "X = df_week2['2018-08-06':].drop('Target2', axis=1)\n",
    "y = df_week2['2018-08-06':]['Target2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2136, 65), (2136,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = ut.train_val_test_split2(X, y, '2022-08-06', '2024-4-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1462, 65), (1462,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# スケーラーを初期化\n",
    "# scaler_X = StandardScaler()\n",
    "# scaler_y = StandardScaler()\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "\n",
    "# トレーニングデータのみに対してフィッティング\n",
    "X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "\n",
    "X_val_scaled = scaler_X.transform(X_val)\n",
    "y_val_scaled = scaler_y.fit_transform(y_val.values.reshape(-1, 1))\n",
    "\n",
    "# テストデータをトレーニングデータのスケールに変換\n",
    "X_test_scaled = scaler_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 欠損値がある場合は補間\n",
    "if np.isnan(X_train_scaled).sum() > 0:\n",
    "    # 平均値で置換\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_train_scaled = imputer.fit_transform(X_train_scaled)\n",
    "\n",
    "if np.isnan(X_val_scaled).sum() > 0:\n",
    "    # 平均値で置換\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_val_scaled = imputer.fit_transform(X_val_scaled)\n",
    "\n",
    "if np.isnan(X_test_scaled).sum() > 0:\n",
    "    # 平均値で置換\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "    X_test_scaled = imputer.fit_transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1462, 65), (1462, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape, y_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルの入力に合わせてデータを整形\n",
    "# X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], X_train_scaled.shape[1], 1))\n",
    "# X_val_scaled = X_val_scaled.reshape((X_val_scaled.shape[0], X_val_scaled.shape[1], 1))\n",
    "# X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], X_test_scaled.shape[1], 1))\n",
    "\n",
    "X_train_scaled = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
    "X_val_scaled = X_val_scaled.reshape((X_val_scaled.shape[0], 1, X_val_scaled.shape[1]))\n",
    "X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1462, 605, 71)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データセットのサイズ確認\n",
    "len(X_train), len(X_val), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1462, 1, 65), (1462, 1), (605, 1, 65), (605, 1), (71, 1, 65))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データセットの形状確認\n",
    "X_train_scaled.shape, y_train_scaled.shape, X_val_scaled.shape, y_val_scaled.shape, X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルパラメータの設定\n",
    "# param_grid = {\n",
    "#     'dense_units': [32, 64, 128, 256, 512, 1028],\n",
    "#     'gru_units': [32, 64, 128, 256, 512, 1028],\n",
    "#     'learning_rate': [0.001],\n",
    "#     'batch_size': [32]\n",
    "# }\n",
    "param_grid = {\n",
    "    'dense_units': [32],\n",
    "    'gru_units': [32],\n",
    "    'learning_rate': [0.001],\n",
    "    'batch_size': [32]\n",
    "}\n",
    "\n",
    "import itertools\n",
    "\n",
    "param_combinations = list(itertools.product(\n",
    "    param_grid['dense_units'],\n",
    "    param_grid['gru_units'],\n",
    "    param_grid['learning_rate'],\n",
    "    param_grid['batch_size']\n",
    "))\n",
    "\n",
    "param_list = []\n",
    "for dense_units, gru_units, learning_rate, batch_size in param_combinations:\n",
    "    params = {\n",
    "        'dense_units': dense_units,\n",
    "        'gru_units': gru_units,\n",
    "        'learning_rate': learning_rate,\n",
    "        'batch_size': batch_size\n",
    "    }\n",
    "    param_list.append(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存先を指定\n",
    "tracking_uri = '/home/code/mlflow/mlruns'\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "experiment_name = \"gru_experiment11\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "# experiment_idを取得\n",
    "experiment_id = mlflow.get_experiment_by_name(experiment_name).experiment_id\n",
    "\n",
    "# mlflowのシステムメトリクスの記録設定\n",
    "os.environ[\"MLFLOW_ENABLE_SYSTEM_METRICS_LOGGING\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 12:02:36.585989: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-11 12:02:36.641047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-11 12:02:36.641681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-11 12:02:36.643145: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-11 12:02:36.645878: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-11 12:02:36.646431: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-11 12:02:36.646809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-11 12:02:38.546663: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-11 12:02:38.547037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-11 12:02:38.547052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1609] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-06-11 12:02:38.547309: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:922] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-06-11 12:02:38.548039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1624 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/11 12:02:39 WARNING mlflow.utils.git_utils: Failed to import Git (the Git executable is probably not on your PATH), so Git SHA is not available. Error: Failed to initialize: Bad git executable.\n",
      "The git executable must be specified in one of the following ways:\n",
      "    - be included in your $PATH\n",
      "    - be set via $GIT_PYTHON_GIT_EXECUTABLE\n",
      "    - explicitly set via git.refresh(<full-path-to-git-executable>)\n",
      "\n",
      "All git commands will error until this is rectified.\n",
      "\n",
      "This initial message can be silenced or aggravated in the future by setting the\n",
      "$GIT_PYTHON_REFRESH environment variable. Use one of the following values:\n",
      "    - quiet|q|silence|s|silent|none|n|0: for no message or exception\n",
      "    - warn|w|warning|log|l|1: for a warning message (logging level CRITICAL, displayed by default)\n",
      "    - error|e|exception|raise|r|2: for a raised exception\n",
      "\n",
      "Example:\n",
      "    export GIT_PYTHON_REFRESH=quiet\n",
      "\n",
      "2024/06/11 12:02:40 WARNING mlflow.system_metrics.system_metrics_monitor: Skip logging GPU metrics because creating `GPUMonitor` failed with error: `pynvml` is not installed, to log GPU metrics please run `pip install pynvml` to install it..\n",
      "2024/06/11 12:02:40 INFO mlflow.system_metrics.system_metrics_monitor: Started monitoring system metrics.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-11 12:02:44.787016: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-06-11 12:02:47.280985: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/46 - 17s - loss: 0.0577 - val_loss: 0.0175 - 17s/epoch - 363ms/step\n",
      "Epoch 2/10000\n",
      "46/46 - 2s - loss: 0.0093 - val_loss: 0.0121 - 2s/epoch - 47ms/step\n",
      "Epoch 3/10000\n",
      "46/46 - 2s - loss: 0.0052 - val_loss: 0.0112 - 2s/epoch - 52ms/step\n",
      "Epoch 4/10000\n",
      "46/46 - 2s - loss: 0.0044 - val_loss: 0.0108 - 2s/epoch - 46ms/step\n",
      "Epoch 5/10000\n",
      "46/46 - 2s - loss: 0.0042 - val_loss: 0.0103 - 2s/epoch - 46ms/step\n",
      "Epoch 6/10000\n",
      "46/46 - 2s - loss: 0.0042 - val_loss: 0.0100 - 2s/epoch - 39ms/step\n",
      "Epoch 7/10000\n",
      "46/46 - 2s - loss: 0.0041 - val_loss: 0.0102 - 2s/epoch - 35ms/step\n",
      "Epoch 8/10000\n",
      "46/46 - 2s - loss: 0.0040 - val_loss: 0.0097 - 2s/epoch - 45ms/step\n",
      "Epoch 9/10000\n",
      "46/46 - 2s - loss: 0.0041 - val_loss: 0.0101 - 2s/epoch - 39ms/step\n",
      "Epoch 10/10000\n",
      "46/46 - 2s - loss: 0.0040 - val_loss: 0.0099 - 2s/epoch - 39ms/step\n",
      "Epoch 11/10000\n",
      "46/46 - 1s - loss: 0.0040 - val_loss: 0.0102 - 1s/epoch - 28ms/step\n",
      "Epoch 12/10000\n",
      "46/46 - 2s - loss: 0.0040 - val_loss: 0.0094 - 2s/epoch - 34ms/step\n",
      "Epoch 13/10000\n",
      "46/46 - 1s - loss: 0.0039 - val_loss: 0.0097 - 1s/epoch - 27ms/step\n",
      "Epoch 14/10000\n",
      "46/46 - 1s - loss: 0.0039 - val_loss: 0.0109 - 998ms/epoch - 22ms/step\n",
      "Epoch 15/10000\n",
      "46/46 - 1s - loss: 0.0039 - val_loss: 0.0102 - 821ms/epoch - 18ms/step\n",
      "Epoch 16/10000\n",
      "46/46 - 1s - loss: 0.0041 - val_loss: 0.0103 - 806ms/epoch - 18ms/step\n",
      "Epoch 17/10000\n",
      "46/46 - 1s - loss: 0.0039 - val_loss: 0.0096 - 693ms/epoch - 15ms/step\n",
      "Epoch 18/10000\n",
      "46/46 - 1s - loss: 0.0038 - val_loss: 0.0096 - 966ms/epoch - 21ms/step\n",
      "Epoch 19/10000\n",
      "46/46 - 1s - loss: 0.0037 - val_loss: 0.0098 - 1s/epoch - 22ms/step\n",
      "Epoch 20/10000\n",
      "46/46 - 1s - loss: 0.0037 - val_loss: 0.0104 - 890ms/epoch - 19ms/step\n",
      "Epoch 21/10000\n",
      "46/46 - 1s - loss: 0.0039 - val_loss: 0.0099 - 755ms/epoch - 16ms/step\n",
      "Epoch 22/10000\n",
      "46/46 - 1s - loss: 0.0038 - val_loss: 0.0094 - 500ms/epoch - 11ms/step\n",
      "Epoch 23/10000\n",
      "46/46 - 0s - loss: 0.0037 - val_loss: 0.0101 - 461ms/epoch - 10ms/step\n",
      "Epoch 24/10000\n",
      "46/46 - 1s - loss: 0.0039 - val_loss: 0.0098 - 598ms/epoch - 13ms/step\n",
      "Epoch 25/10000\n",
      "46/46 - 0s - loss: 0.0038 - val_loss: 0.0096 - 498ms/epoch - 11ms/step\n",
      "Epoch 26/10000\n",
      "46/46 - 0s - loss: 0.0037 - val_loss: 0.0099 - 462ms/epoch - 10ms/step\n",
      "Epoch 27/10000\n",
      "46/46 - 0s - loss: 0.0038 - val_loss: 0.0107 - 478ms/epoch - 10ms/step\n",
      "Epoch 28/10000\n",
      "46/46 - 0s - loss: 0.0038 - val_loss: 0.0097 - 493ms/epoch - 11ms/step\n",
      "Epoch 29/10000\n",
      "46/46 - 1s - loss: 0.0036 - val_loss: 0.0099 - 505ms/epoch - 11ms/step\n",
      "Epoch 30/10000\n",
      "46/46 - 0s - loss: 0.0036 - val_loss: 0.0101 - 486ms/epoch - 11ms/step\n",
      "Epoch 31/10000\n",
      "46/46 - 1s - loss: 0.0035 - val_loss: 0.0097 - 506ms/epoch - 11ms/step\n",
      "Epoch 32/10000\n",
      "46/46 - 0s - loss: 0.0035 - val_loss: 0.0105 - 480ms/epoch - 10ms/step\n",
      "Epoch 33/10000\n",
      "46/46 - 1s - loss: 0.0035 - val_loss: 0.0099 - 504ms/epoch - 11ms/step\n",
      "Epoch 34/10000\n",
      "46/46 - 1s - loss: 0.0035 - val_loss: 0.0098 - 503ms/epoch - 11ms/step\n",
      "Epoch 35/10000\n",
      "46/46 - 0s - loss: 0.0040 - val_loss: 0.0107 - 497ms/epoch - 11ms/step\n",
      "Epoch 36/10000\n",
      "46/46 - 0s - loss: 0.0035 - val_loss: 0.0098 - 479ms/epoch - 10ms/step\n",
      "Epoch 37/10000\n",
      "46/46 - 0s - loss: 0.0035 - val_loss: 0.0111 - 467ms/epoch - 10ms/step\n",
      "Epoch 38/10000\n",
      "46/46 - 1s - loss: 0.0036 - val_loss: 0.0101 - 517ms/epoch - 11ms/step\n",
      "Epoch 39/10000\n",
      "46/46 - 0s - loss: 0.0035 - val_loss: 0.0098 - 488ms/epoch - 11ms/step\n",
      "Epoch 40/10000\n",
      "46/46 - 0s - loss: 0.0034 - val_loss: 0.0100 - 489ms/epoch - 11ms/step\n",
      "Epoch 41/10000\n",
      "46/46 - 0s - loss: 0.0034 - val_loss: 0.0102 - 461ms/epoch - 10ms/step\n",
      "Epoch 42/10000\n",
      "46/46 - 0s - loss: 0.0033 - val_loss: 0.0099 - 473ms/epoch - 10ms/step\n",
      "Epoch 43/10000\n",
      "46/46 - 0s - loss: 0.0034 - val_loss: 0.0107 - 493ms/epoch - 11ms/step\n",
      "Epoch 44/10000\n",
      "46/46 - 0s - loss: 0.0035 - val_loss: 0.0108 - 477ms/epoch - 10ms/step\n",
      "Epoch 45/10000\n",
      "46/46 - 1s - loss: 0.0032 - val_loss: 0.0101 - 511ms/epoch - 11ms/step\n",
      "Epoch 46/10000\n",
      "46/46 - 0s - loss: 0.0033 - val_loss: 0.0110 - 486ms/epoch - 11ms/step\n",
      "Epoch 47/10000\n",
      "46/46 - 0s - loss: 0.0035 - val_loss: 0.0099 - 440ms/epoch - 10ms/step\n",
      "Epoch 48/10000\n",
      "46/46 - 0s - loss: 0.0034 - val_loss: 0.0103 - 485ms/epoch - 11ms/step\n",
      "Epoch 49/10000\n",
      "46/46 - 0s - loss: 0.0033 - val_loss: 0.0099 - 497ms/epoch - 11ms/step\n",
      "Epoch 50/10000\n",
      "46/46 - 0s - loss: 0.0033 - val_loss: 0.0103 - 483ms/epoch - 11ms/step\n",
      "Epoch 51/10000\n",
      "46/46 - 0s - loss: 0.0033 - val_loss: 0.0104 - 476ms/epoch - 10ms/step\n",
      "Epoch 52/10000\n",
      "46/46 - 1s - loss: 0.0031 - val_loss: 0.0103 - 522ms/epoch - 11ms/step\n",
      "Epoch 53/10000\n",
      "46/46 - 1s - loss: 0.0032 - val_loss: 0.0100 - 513ms/epoch - 11ms/step\n",
      "Epoch 54/10000\n",
      "46/46 - 0s - loss: 0.0033 - val_loss: 0.0109 - 486ms/epoch - 11ms/step\n",
      "Epoch 55/10000\n",
      "46/46 - 0s - loss: 0.0032 - val_loss: 0.0099 - 469ms/epoch - 10ms/step\n",
      "Epoch 56/10000\n",
      "46/46 - 0s - loss: 0.0031 - val_loss: 0.0104 - 475ms/epoch - 10ms/step\n",
      "Epoch 57/10000\n",
      "46/46 - 0s - loss: 0.0033 - val_loss: 0.0102 - 450ms/epoch - 10ms/step\n",
      "Epoch 58/10000\n",
      "46/46 - 0s - loss: 0.0033 - val_loss: 0.0102 - 464ms/epoch - 10ms/step\n",
      "Epoch 59/10000\n",
      "46/46 - 1s - loss: 0.0031 - val_loss: 0.0103 - 534ms/epoch - 12ms/step\n",
      "Epoch 60/10000\n",
      "46/46 - 0s - loss: 0.0032 - val_loss: 0.0101 - 480ms/epoch - 10ms/step\n",
      "Epoch 61/10000\n",
      "46/46 - 0s - loss: 0.0030 - val_loss: 0.0104 - 484ms/epoch - 11ms/step\n",
      "Epoch 62/10000\n",
      "46/46 - 0s - loss: 0.0031 - val_loss: 0.0105 - 489ms/epoch - 11ms/step\n",
      "19/19 [==============================] - 0s 6ms/step - loss: 0.0094\n",
      "val_loss: 0.009389818646013737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/06/11 12:03:52 INFO mlflow.system_metrics.system_metrics_monitor: Stopping system metrics monitoring...\n",
      "2024/06/11 12:03:52 INFO mlflow.system_metrics.system_metrics_monitor: Successfully terminated system metrics monitoring!\n"
     ]
    }
   ],
   "source": [
    "# モデルパラメータ\n",
    "for params in param_list:\n",
    "    dense_units = params['dense_units']\n",
    "    gru_units = params['gru_units']\n",
    "    learning_rate = params['learning_rate']\n",
    "    batch_size = params['batch_size']\n",
    "\n",
    "    # モデルの構築\n",
    "    model = gru.GRU_single(input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2]), \n",
    "                          dense_units=dense_units, \n",
    "                          gru_units=gru_units, \n",
    "                          lr=learning_rate\n",
    "                        )\n",
    "    # モデルの視覚化\n",
    "    plot_model(model,show_shapes=True) \n",
    "    \n",
    "    # EarlyStoppingの設定\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=40, restore_best_weights=True)\n",
    "\n",
    "    with mlflow.start_run(experiment_id=experiment_id):\n",
    "        # モデルの訓練\n",
    "        history = model.fit(X_train_scaled, y_train_scaled, epochs=10000, batch_size=batch_size, validation_data=(X_val_scaled, y_val_scaled), callbacks=[early_stopping], verbose=2)\n",
    "        \n",
    "        # 検証データでの損失を評価\n",
    "        val_loss = model.evaluate(X_val_scaled, y_val_scaled)\n",
    "        print(f'val_loss: {val_loss}')\n",
    "\n",
    "        # モデルの保存\n",
    "        model.save('/home/code/mlflow/artifacts/models/keras_model.h5')\n",
    "\n",
    "        # モデルのパラメータを記録\n",
    "        mlflow.log_param('dense_units', dense_units)\n",
    "        mlflow.log_param('gru_units', gru_units)\n",
    "        # mlflow.log_param('learning_rate', learning_rate)\n",
    "        mlflow.log_param('batch_size', batch_size)\n",
    "\n",
    "        # 損失を記録\n",
    "        mlflow.log_metric('last_val_loss', val_loss)\n",
    "\n",
    "        for epoch in range(len(history.history['loss'])):\n",
    "            mlflow.log_metric('train_loss', history.history['loss'][epoch], step=epoch)\n",
    "            mlflow.log_metric('val_loss', history.history['val_loss'][epoch], step=epoch)\n",
    "\n",
    "        # X_val, X_testに対する予測結果をcsvで保存\n",
    "        df_val = X_val.copy()\n",
    "        y_val_pred = model.predict(X_val_scaled)\n",
    "        y_val_pred = scaler_y.inverse_transform(y_val_pred)\n",
    "        y_val_, y_val_pred_ = ut.Target2_transform(X_val, y_val, y_val_pred)\n",
    "        df_val['Ans'] = y_val_\n",
    "        df_val['Pred'] = y_val_pred_\n",
    "        \n",
    "        df_test = X_test.copy()\n",
    "        y_test_pred = model.predict(X_test_scaled)\n",
    "        y_test_pred = scaler_y.inverse_transform(y_test_pred)\n",
    "        y_test_, y_test_pred_ = ut.Target2_transform(X_test, y_test, y_test_pred)\n",
    "        df_test['Ans'] = y_test_\n",
    "        df_test['Pred'] = y_test_pred_\n",
    "\n",
    "        # df_valにおいて、誤差と絶対誤差を計算\n",
    "        df_val['Error'] = df_val['Ans'] - df_val['Pred']\n",
    "        df_val['Abs Error'] = abs(df_val['Error'])\n",
    "\n",
    "        # 最大誤差、最小誤差、平均誤差を計算（Abs Errorが0の行を除いて計算）\n",
    "        val_max_error = df_val[df_val['Abs Error'] != 0]['Abs Error'].max()\n",
    "        val_min_error = df_val[df_val['Abs Error'] != 0]['Abs Error'].min()\n",
    "        val_mean_abs_error = df_val[df_val['Abs Error'] != 0]['Abs Error'].mean()\n",
    "        mlflow.log_metric('val_max_error', val_max_error)\n",
    "        mlflow.log_metric('val_min_error', val_min_error)\n",
    "        mlflow.log_metric('val_mean_abs_error', val_mean_abs_error)\n",
    "\n",
    "        df_val.to_csv('/home/code/mlflow/artifacts/csv/val_pred.csv')\n",
    "        mlflow.log_artifact('/home/code/mlflow/artifacts/csv/val_pred.csv')\n",
    "        df_test.to_csv('/home/code/mlflow/artifacts/csv/test_pred.csv')\n",
    "        mlflow.log_artifact('/home/code/mlflow/artifacts/csv/test_pred.csv')\n",
    "\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(df_val['Ans'], label='Actual')\n",
    "        plt.plot(df_val['Pred'], label='Predict')\n",
    "        plt.legend()\n",
    "        plt.savefig('/home/code/mlflow/artifacts/images/val_pred.png')\n",
    "        mlflow.log_artifact('/home/code/mlflow/artifacts/images/val_pred.png')\n",
    "        plt.close()\n",
    "\n",
    "        # モデルの保存\n",
    "        mlflow.log_artifact('/home/code/mlflow/artifacts/models/keras_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
